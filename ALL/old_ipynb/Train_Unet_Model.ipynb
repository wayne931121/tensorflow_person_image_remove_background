{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9059110b",
   "metadata": {},
   "source": [
    "# 訓練模組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9890c2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "027228fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9864cd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_train(point, batch_size, total):\n",
    "    batch_size -= 1 # Inclube start point  \n",
    "    if(point+batch_size>total):\n",
    "        f = point+batch_size-total\n",
    "        g = point+batch_size+1-f\n",
    "        return list(range(point,g))+list(range(0, f))\n",
    "    else:\n",
    "        g = point+batch_size+1\n",
    "        return list(range(point,g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32510acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_point = 0\n",
    "val_point = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b840c4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag(point, batch_size, data_size):\n",
    "    #Choose random indice for later picking.\n",
    "    rnd_ind = on_train(point, batch_size, data_size-1)\n",
    "    if((point + batch_size) >= data_size):\n",
    "        point = point + batch_size - data_size\n",
    "    else:\n",
    "        point = point + batch_size \n",
    "    return  rnd_ind, point   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b78383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(img_np, mode, size):\n",
    "    # 變化數 (C 4取0)+(C 4取1)+(C 4取2)+(C 4取3)+(C 4取4)\n",
    "    s = img_np.shape\n",
    "    if mode==\"left\":\n",
    "        width = s[1]+size\n",
    "        height = s[0]\n",
    "        s1 = np.zeros((height, width))\n",
    "        s1[0:height, size:width] = img_np\n",
    "    if mode==\"right\":\n",
    "        width = s[1]+size\n",
    "        height = s[0]\n",
    "        s1 = np.zeros((height, width))\n",
    "        s1[0:height, 0:s[1]] = img_np\n",
    "    if mode==\"top\":\n",
    "        width = s[1]\n",
    "        height = s[0]+size\n",
    "        s1 = np.zeros((height, width))\n",
    "        s1[size:height, 0:width] = img_np\n",
    "    if mode==\"down\":\n",
    "        width = s[1]\n",
    "        height = s[0]+size\n",
    "        s1 = np.zeros((height, width))\n",
    "        s1[0:s[0], 0:width] = img_np\n",
    "    img_np = cv2.resize(s1, s)\n",
    "    return img_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4993684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = [256, 256, 1]\n",
    "\n",
    "def data_generator(isTrain, images_path, masks_path, image_ids, mask_ids, batch_size, img_size=input_size):\n",
    "    global train_point, val_point\n",
    "    '''\n",
    "    images_path/masks_path: Images/Masks folder directory.\n",
    "    images_ids/mask_ids: Ids for '.jpg' images/masks.\n",
    "    img_size: Generated imgs/masks size.\n",
    "    \n",
    "    returns: batch of randomly-selected car&mask images value-scaled (0 -> 1). \n",
    "    '''\n",
    "    data_size = len(image_ids)\n",
    "    while True:\n",
    "        #Choose random indice for later picking.        \n",
    "        if isTrain:\n",
    "            rnd_ind, point = flag(train_point, batch_size, data_size)\n",
    "            train_point = point\n",
    "        else:\n",
    "            rnd_ind, point = flag(val_point, batch_size, data_size)\n",
    "            val_point = point\n",
    "        imgs = []\n",
    "        masks = []\n",
    "        for i in rnd_ind:\n",
    "            #Pick a random id for car&mask images.\n",
    "            img_id, mask_id = image_ids[i], mask_ids[i]\n",
    "            #Load/resize images.\n",
    "            # print(images_path +\"\\\\\" + img_id)\n",
    "            img = cv2.imread(images_path +\"\\\\\" + img_id, cv2.IMREAD_GRAYSCALE)\n",
    "            mask = cv2.imread(masks_path +\"\\\\\" + mask_id, cv2.IMREAD_GRAYSCALE)            \n",
    "            #Add to the batch data.\n",
    "            # 用隨機數判斷是否透視圖片，增強訓練集 (幅度30%以內) add on 2022/5/7 13:04\n",
    "            ctr = np.random.randint(0,2)\n",
    "            if ctr==1:\n",
    "                Perspective = True\n",
    "                scale = 0.3/2\n",
    "                s1 = int(img_size[1]*scale)\n",
    "                s2 = int(img_size[0]*scale)\n",
    "                x1 = np.random.randint(-s1,s1)\n",
    "                x2 = np.random.randint(-s1,s1)\n",
    "                x3 = img_size[1]-np.random.randint(-s1,s1)\n",
    "                x4 = img_size[1]-np.random.randint(-s1,s1)\n",
    "                y1 = np.random.randint(-s2,s2)\n",
    "                y2 = img_size[0]-np.random.randint(-s2,s2)\n",
    "                y3 = img_size[0]-np.random.randint(-s2,s2)\n",
    "                y4 = np.random.randint(-s2,s2)\n",
    "                pts1 = np.float32([[0,0], [0, img_size[0]], [img_size[1], img_size[0]], [img_size[1], 0]])\n",
    "                pts2 = np.float32([[x1,y1], [x2, y2], [x3, y3], [x4, y4]])\n",
    "                M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "                img = cv2.warpPerspective(img,M,(img_size[1],img_size[0]))\n",
    "                mask = cv2.warpPerspective(mask,M,(img_size[1],img_size[0]))\n",
    "            # 用隨機數判斷是否旋轉圖片，增強訓練集\n",
    "            ctr = np.random.randint(0,2)\n",
    "            if ctr==1: # add on 2022/4/30\n",
    "                inf = (int(img_size[0]/2), int(img_size[1]/2))\n",
    "                inf1 = (int(img_size[0]), int(img_size[1]))\n",
    "                M = cv2.getRotationMatrix2D(inf, np.random.randint(0,361), 1.0)\n",
    "                img = cv2.warpAffine(img, M, inf1)\n",
    "                mask = cv2.warpAffine(mask, M, inf1)\n",
    "            ctr = np.random.randint(0,3)\n",
    "            if ctr==1:\n",
    "                # 水平翻轉\n",
    "                img = cv2.flip(img, 1)\n",
    "                mask = cv2.flip(mask, 1)\n",
    "            elif ctr==2:\n",
    "                # 上下翻轉\n",
    "                img = cv2.flip(img, 0)\n",
    "                mask = cv2.flip(mask, 0)\n",
    "            # 對圖片做裁切 ( 幅度30%以內 )\n",
    "            scale = 0.3/2\n",
    "            ctr = np.random.randint(0,4)\n",
    "            if ctr==1 or ctr==3: # add on 2022/4/30\n",
    "                ymin = 0 + np.random.randint(0,int(img_size[0]*scale))\n",
    "                ymax = img_size[1] - np.random.randint(0,int(img_size[0]*scale))\n",
    "                xmin = 0 + np.random.randint(0,int(img_size[1]*scale))\n",
    "                xmax = img_size[0] - np.random.randint(0,int(img_size[1]*scale))\n",
    "                img = img[ymin:ymax, xmin:xmax]\n",
    "                mask = mask[ymin:ymax, xmin:xmax] \n",
    "                img = cv2.resize(img,(img_size[0], img_size[1]))\n",
    "                mask = cv2.resize(mask,(img_size[0], img_size[1]))\n",
    "            elif ctr==2 or ctr==3: # add on 2022/5/7\n",
    "                # 對圖片做填充 ( 幅度50%以內 )\n",
    "                scale = 0.5/2\n",
    "                s = np.random.randint(0, int(img_size[0]*scale))\n",
    "                img = padding(img, \"top\", s)\n",
    "                mask = padding(mask, \"top\", s)\n",
    "                s = np.random.randint(0, int(img_size[0]*scale))\n",
    "                img = padding(img, \"down\", s)\n",
    "                mask = padding(mask, \"down\", s)\n",
    "                s = np.random.randint(0, int(img_size[1]*scale))\n",
    "                img = padding(img, \"left\", s)\n",
    "                mask = padding(mask, \"left\", s)\n",
    "                s = np.random.randint(0, int(img_size[1]*scale))\n",
    "                img = padding(img, \"right\", s)\n",
    "                mask = padding(mask, \"right\", s)\n",
    "            # 對圖片做亮度、對比度處理，增強訓練集\n",
    "            # 參考網站 https://www.wongwonggoods.com/python/python_opencv/opencv-modify-contrast/\n",
    "            ctr = np.random.randint(1,101)\n",
    "            if ctr>=35: # 65% 機率調整對比度\n",
    "                brightness = 0\n",
    "                contrast = np.random.randint(1,71) # - 減少對比度/+ 增加對比度      \n",
    "                if ctr>=67.5:\n",
    "                    contrast = contrast*-1\n",
    "                B = brightness / 255.0\n",
    "                c = contrast / 255.0 \n",
    "                k = math.tan((45 + 44 * c) / 180 * math.pi)                \n",
    "                img = (img - 127.5 * (1 - B)) * k + 127.5 * (1 + B)\n",
    "                # 所有值必須介於 0~255 之間，超過255 = 255，小於 0 = 0\n",
    "                img = np.clip(img, 0, 255)  \n",
    "            ctr = np.random.randint(1,101)    \n",
    "            if ctr>=35: # 65% 機率調整亮度\n",
    "                phi = np.random.randint(5,16)/10 # phi>1 減少亮度  phi<1 增加亮度 phi:0.5~1.5\n",
    "                img = (img/255)**phi\n",
    "                img = np.clip(img*255, 0, 255)  \n",
    "            ctr = np.random.randint(0,2)\n",
    "            if ctr==1 : # 50% 機率黑白顛倒\n",
    "                img = 255-img\n",
    "            img = img.reshape(img_size[0], img_size[1], 1)    \n",
    "            mask = mask.reshape(img_size[0], img_size[1], 1)                \n",
    "            imgs.append(img)\n",
    "            masks.append(mask)   \n",
    "        yield np.array(imgs, dtype=np.float16) / 255., np.array(masks, dtype=np.float16) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f143ae34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    '''\n",
    "    Metric\n",
    "    '''\n",
    "    smooth = 1.\n",
    "    y_true = tf.where(y_true>0.5,1,0)\n",
    "    y_true = tf.cast(y_true,dtype=tf.float32)\n",
    "    y_pred = tf.where(y_pred>0.5,1,0)\n",
    "    y_pred = tf.cast(y_pred,dtype=tf.float32)\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    '''\n",
    "    Loss function\n",
    "    '''\n",
    "    loss = 1 - dice_coef(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    '''\n",
    "    Mixed crossentropy and dice loss.\n",
    "    '''\n",
    "    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bfeb9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_desktop_ini(lst):\n",
    "    i = 0\n",
    "    for _ in lst:\n",
    "        if _==\"desktop.ini\":\n",
    "            lst.pop(i)\n",
    "            break\n",
    "        i += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f8c4690",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgPath = r\"C:\\Users\\sky66\\fiftyone\\coco-2017\\raw\\img\"\n",
    "maskPath = r\"C:\\Users\\sky66\\fiftyone\\coco-2017\\raw\\mask\"\n",
    "\n",
    "# 放mask\n",
    "masks = list(os.listdir(maskPath))\n",
    "\n",
    "# 放新圖片\n",
    "images = list(os.listdir(imgPath))\n",
    "\n",
    "remove_desktop_ini(masks)\n",
    "remove_desktop_ini(images)\n",
    "\n",
    "masks = sorted(masks)\n",
    "images = sorted(images)\n",
    "\n",
    "train = int(len(masks)*0.8)\n",
    "val = len(images)-train\n",
    "\n",
    "train_img = images[0:train]\n",
    "train_mask = masks[0:train]\n",
    "\n",
    "val_img = images[train:]\n",
    "val_mask = masks[train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5fab16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for e,r in zip(train_img, train_mask):\n",
    "#     print(e, \" \",r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9442ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13010\n",
      "13010\n"
     ]
    }
   ],
   "source": [
    "print(len(images))\n",
    "print(len(masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fada33a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for e,r in zip(val_img, val_mask):\n",
    "#     print(e, \" \",r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f6a5f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(ids, images_path=imgPath, masks_path=maskPath, imgIds=images, maskIds=masks, img_size=[256,256,1]):\n",
    "    img_id = imgIds[ids]\n",
    "    mask_id = maskIds[ids]\n",
    "    img = load_img(images_path +\"\\\\\" + img_id, target_size=img_size[:-1], color_mode = 'grayscale')\n",
    "    mask = load_img(masks_path +\"\\\\\" + mask_id, target_size=img_size[:-1], color_mode = 'grayscale')\n",
    "    img = img_to_array(img)\n",
    "    mask = img_to_array(mask)    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(50,50))\n",
    "    ax[0].imshow(img, cmap='gray')\n",
    "    ax[0].axis('off')\n",
    "    ax[1].imshow(mask, cmap='gray')\n",
    "    ax[1].axis('off')\n",
    "    plt.show()\n",
    "    return img\n",
    "# a = test(35)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30ba1adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = r'C:\\Users\\sky66\\Desktop\\my_model'\n",
    "\n",
    "uNet = tf.keras.models.load_model(modelPath, custom_objects={\"dice_coef\":dice_coef, \"dice_loss\":dice_loss, \"bce_dice_loss\":bce_dice_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0d498ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelPath1 = r'C:\\Users\\sky66\\Desktop\\my_model1'\n",
    "\n",
    "# uNet1 = tf.keras.models.load_model(modelPath, custom_objects={\"dice_coef\":dice_coef, \"dice_loss\":dice_loss, \"bce_dice_loss\":bce_dice_loss})\n",
    "\n",
    "# uNet.set_weights(uNet1.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63b5bec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare callbacks\n",
    "patience = 100\n",
    "LR_callback = ReduceLROnPlateau(monitor='val_loss', patience=patience, verbose=10, factor=0.5, min_lr=1e-030)\n",
    "EarlyStop_callback = EarlyStopping(monitor='val_loss',patience=100, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9533f787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perpare data generators.\n",
    "batch_size = 5\n",
    "train_gen = data_generator(True, imgPath, maskPath, train_img, train_mask, batch_size=batch_size)\n",
    "val_gen = data_generator(False, imgPath, maskPath, val_img, val_mask, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d89fd653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1e-05 9e-5 4.5e-6 5e-06 2.5e-06 1.25e-06 6.25e-07 3.125e-07 1.5625e-07\n",
    "lr = 1e-05\n",
    "# uNet.compile(optimizer=Adam(learning_rate=lr), loss=bce_dice_loss, metrics=[dice_coef])\n",
    "uNet.compile(optimizer=RMSprop(learning_rate=lr), loss=bce_dice_loss, metrics=[dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb2977f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2081/2081 [==============================] - 603s 287ms/step - loss: 0.4520 - dice_coef: 0.8588 - val_loss: 0.4368 - val_dice_coef: 0.8639 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "history = uNet.fit(train_gen, steps_per_epoch=int(train/batch_size),\n",
    "                             epochs=1, validation_data=val_gen,\n",
    "                             validation_steps=int(val/batch_size),\n",
    "                             callbacks=[LR_callback, EarlyStop_callback])\n",
    "#uNet.save(modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f2e2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=list(range(len(history.history['dice_coef'])))\n",
    "txt = \"Unet Model\\ndate:2022-05-07-03:48 a.m.\\nlearning-rate: 1e-05\\noptimizer:RMSprop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fa9a3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(x,history.history['dice_coef'],label=\"dice_coef\")\n",
    "plt.plot(x,history.history['val_dice_coef'],label=\"val_dice_coef\")\n",
    "\n",
    "plt.title(txt,fontsize=15)\n",
    "plt.xlabel(\"Epochs\",fontsize=13)\n",
    "plt.ylabel(\"Y\",fontsize=13)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f564c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,history.history['loss'],label=\"loss\")\n",
    "plt.plot(x,history.history['val_loss'],label=\"val_loss\")\n",
    "\n",
    "plt.title(txt,fontsize=15)\n",
    "plt.xlabel(\"Epochs\",fontsize=13)\n",
    "plt.ylabel(\"Y\",fontsize=13)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010632fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(1.25e-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c008dfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"%.10f\"%(1.25e-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0927ae3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\sky66\\Desktop\\my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "uNet.save(modelPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90932094",
   "metadata": {},
   "source": [
    "# 進行偵測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41efde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f93ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "        \n",
    "def dice_coef(y_true, y_pred):\n",
    "    '''\n",
    "    Metric\n",
    "    '''\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    '''\n",
    "    Loss function\n",
    "    '''\n",
    "    loss = 1 - dice_coef(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    '''\n",
    "    Mixed crossentropy and dice loss.\n",
    "    '''\n",
    "    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42637421",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = r'C:\\Users\\sky66\\Desktop\\my_model'\n",
    "uNet = tf.keras.models.load_model(modelPath, custom_objects={\"dice_coef\":dice_coef, \"dice_loss\":dice_loss, \"bce_dice_loss\":bce_dice_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a341df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(img, contrast): # contrast - 減少對比度/+ 增加對比度     \n",
    "    # 調整對比度\n",
    "    brightness = 0\n",
    "    B = brightness / 255.0\n",
    "    c = contrast / 255.0 \n",
    "    k = math.tan((45 + 44 * c) / 180 * math.pi)                \n",
    "    img = (img - 127.5 * (1 - B)) * k + 127.5 * (1 + B)\n",
    "    # 所有值必須介於 0~255 之間，超過255 = 255，小於 0 = 0\n",
    "    img = np.clip(img, 0, 255)    \n",
    "    return img\n",
    "\n",
    "def cv2_to_plt(img_np):\n",
    "    img_np = cv2.cvtColor(img_np, cv2.COLOR_BGR2RGB)\n",
    "    img_np = img_np/255\n",
    "    return img_np\n",
    "\n",
    "def plt_to_cv2(img_np):\n",
    "    return cv2.cvtColor((img_np*255).astype(\"uint8\"), cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "def pred(img_path):    \n",
    "    # load\n",
    "    img_np = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.imread(img_path)\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    img_np = cv2.resize(img_np, (256,256))\n",
    "    \n",
    "    # use to predict\n",
    "    # img_np = 255-img_np\n",
    "    # print(img_np.shape)\n",
    "    # img_np = phi(img_np, 100)\n",
    "    img_np = img_np/255\n",
    "    img_np = np.reshape(img_np,(256,256,1))\n",
    "    img_np = np.expand_dims(img_np, 0)\n",
    "    \n",
    "    # predict\n",
    "    pred_mask = uNet.predict(img_np)\n",
    "    pred_mask = pred_mask[0]\n",
    "    \n",
    "    # process image\n",
    "    # mask is GRAYSCALE\n",
    "    pred_mask = pred_mask*255\n",
    "    pred_mask = cv2.resize(pred_mask, (width,height))\n",
    "    pred_mask = pred_mask/255\n",
    "    pred_mask = np.reshape(pred_mask,(height,width,1))\n",
    "    img = cv2_to_plt(img)\n",
    "      \n",
    "    return pred_mask*255, plt_to_cv2(img), plt_to_cv2(img*pred_mask)\n",
    "\n",
    "def view(img_path):\n",
    "    pred_mask, img, res = pred(img_path)\n",
    "    img = cv2_to_plt(img)\n",
    "    pred_mask /= 255\n",
    "    # view\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(80,80))\n",
    "    ax[0].imshow(img)\n",
    "    ax[0].axis('off')\n",
    "    ax[1].imshow(pred_mask, cmap='gray')\n",
    "    ax[1].axis('off')\n",
    "    # ax[2].imshow(pred_img*np.where(pred_mask>0.1, 1, 0))\n",
    "    ax[2].imshow(img*pred_mask)\n",
    "    ax[2].axis('off')\n",
    "    plt.show()      \n",
    "    \n",
    "def stored(path, store = r\"C:\\Users\\sky66\\Desktop\\predict\"):\n",
    "    name = path.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "    a,b,c = pred(path)\n",
    "    cv2.imwrite(store+\"\\\\\"+name+\"_image.jpg\", b)\n",
    "    cv2.imwrite(store+\"\\\\\"+name+\"_mask.jpg\", a)   \n",
    "    cv2.imwrite(store+\"\\\\\"+name+\"_predict.jpg\", c)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3d0a69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\sky66\\Desktop\\Model\\predict\"+\"\\\\\"\n",
    "for i in os.listdir(path):\n",
    "    if i.split(\".\")[0].split(\"_\")[-1] != \"image\":\n",
    "        continue\n",
    "    f = path+i\n",
    "    view(f)\n",
    "    input(\"Press Enter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e7d8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\sky66\\fiftyone\\coco-2017\\raw\\train2017\"+\"\\\\\"\n",
    "for i in os.listdir(path):\n",
    "    f = path+i\n",
    "    view(f)\n",
    "    input(\"Press Enter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2cd33d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv2.imread(\"C:\\\\Users\\\\sky66\\\\fiftyone\\\\coco-2017\\\\mask\\\\0013ea2087020901 - 複製.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b71dd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_img(\"C:\\\\Users\\\\sky66\\\\fiftyone\\\\coco-2017\\\\mask\\\\0013ea2087020901 - 複製.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defb0016",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(os.listdir(\"C:\\\\Users\\\\sky66\\\\fiftyone\\\\coco-2017\\\\mask\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8994b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in images:\n",
    "#     f = imgPath+\"\\\\\"+i\n",
    "#     f = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "#     if f.shape!=(256,256):\n",
    "#         print(i, f.shape)\n",
    "#         f = cv2.resize(f,(256,256))\n",
    "#         cv2.imwrite(imgPath+\"\\\\\"+i, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e975180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in masks:\n",
    "#     f = maskPath+\"\\\\\"+i\n",
    "#     f = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "#     if f.shape!=(256,256):\n",
    "#         print(i, f.shape)\n",
    "#         f = cv2.resize(f,(256,256))\n",
    "#         cv2.imwrite(maskPath+\"\\\\\"+i, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
