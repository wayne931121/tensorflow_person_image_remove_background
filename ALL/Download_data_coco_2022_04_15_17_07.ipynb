{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12732ba4",
   "metadata": {},
   "source": [
    "# 接續image_process_view_csv.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8199e7",
   "metadata": {},
   "source": [
    "# 下載資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bd97594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 參考網站\n",
    "# https://towardsdatascience.com/master-the-coco-dataset-for-semantic-image-segmentation-part-1-of-2-732712631047\n",
    "# https://cocodataset.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cf91b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2931e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'train' to 'C:\\Users\\sky66\\fiftyone\\coco-2017\\train' if necessary\n",
      "Found annotations at 'C:\\Users\\sky66\\fiftyone\\coco-2017\\raw\\instances_train2017.json'\n",
      "Downloading 64115 images\n",
      "  22% |███|----------| 13891/64115 [26.2m elapsed, 1.6h remaining, 9.0 images/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    852\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 853\u001b[1;33m                 \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    854\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14564/501400481.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m dataset = fiftyone.zoo.load_zoo_dataset(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;34m\"coco-2017\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0msplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mlabel_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"segmentations\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"person\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\fiftyone\\zoo\\datasets\\__init__.py\u001b[0m in \u001b[0;36mload_zoo_dataset\u001b[1;34m(name, split, splits, label_field, dataset_name, dataset_dir, download_if_necessary, drop_existing_dataset, overwrite, cleanup, **kwargs)\u001b[0m\n\u001b[0;32m    195\u001b[0m         )\n\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m         info, dataset_dir = download_zoo_dataset(\n\u001b[0m\u001b[0;32m    198\u001b[0m             \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m             \u001b[0msplits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msplits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\fiftyone\\zoo\\datasets\\__init__.py\u001b[0m in \u001b[0;36mdownload_zoo_dataset\u001b[1;34m(name, split, splits, dataset_dir, overwrite, cleanup, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     )\n\u001b[1;32m--> 116\u001b[1;33m     return zoo_dataset.download_and_prepare(\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[0mdataset_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0msplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\fiftyone\\zoo\\datasets\\__init__.py\u001b[0m in \u001b[0;36mdownload_and_prepare\u001b[1;34m(self, dataset_dir, split, splits, overwrite, cleanup)\u001b[0m\n\u001b[0;32m   1002\u001b[0m                     \u001b[0mnum_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1003\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m                 ) = self._download_and_prepare(split_dir, scratch_dir, split)\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m                 \u001b[1;31m# Add split to ZooDatasetInfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\fiftyone\\zoo\\datasets\\base.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[1;34m(self, dataset_dir, scratch_dir, split)\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_download_and_prepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscratch_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 770\u001b[1;33m         num_samples, classes, downloaded = fouc.download_coco_dataset_split(\n\u001b[0m\u001b[0;32m    771\u001b[0m             \u001b[0mdataset_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    772\u001b[0m             \u001b[0msplit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\fiftyone\\utils\\coco.py\u001b[0m in \u001b[0;36mdownload_coco_dataset_split\u001b[1;34m(dataset_dir, split, year, label_types, classes, image_ids, num_workers, shuffle, seed, max_samples, raw_dir, scratch_dir)\u001b[0m\n\u001b[0;32m   1664\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1665\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnum_download\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1666\u001b[1;33m             \u001b[0m_download_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownload_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1667\u001b[0m             \u001b[0mdid_download\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\fiftyone\\utils\\coco.py\u001b[0m in \u001b[0;36m_download_images\u001b[1;34m(images_dir, image_ids, images, num_workers)\u001b[0m\n\u001b[0;32m   1844\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mfou\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProgressBar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miters_str\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"images\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1845\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdummy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1846\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_do_download\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1847\u001b[0m                     \u001b[0mpb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    856\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 858\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    859\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = fiftyone.zoo.load_zoo_dataset(\n",
    "    \"coco-2017\",\n",
    "    split=\"train\",\n",
    "    label_types=[\"segmentations\"],\n",
    "    classes=[\"person\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b3b18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fiftyone.zoo.load_zoo_dataset(\n",
    "    \"coco-2017\",\n",
    "    split=\"validation\",\n",
    "    label_types=[\"segmentations\"],\n",
    "    classes=[\"person\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2c8480",
   "metadata": {},
   "source": [
    "# 調整圖片大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f7a3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# 放舊圖片的資料夾\n",
    "old = r\"C:\\Users\\sky66\\fiftyone\\coco-2017\\validation\\data\"\n",
    "old1 = r\"C:\\Users\\sky66\\fiftyone\\coco-2017\\train\\data\"\n",
    "# 放新圖片的新資料夾\n",
    "images = r\"C:\\Users\\sky66\\fiftyone\\coco-2017\\new\"\n",
    "size = (256,256)\n",
    "for e in os.listdir(old):\n",
    "    fil = old+\"\\\\\"+e\n",
    "    fil1 = images+\"\\\\val_\"+e\n",
    "    a = cv2.imread(fil)\n",
    "    a = cv2.resize(a, size)\n",
    "    cv2.imwrite(fil1, a)\n",
    "for e in os.listdir(old1):\n",
    "    fil = old1+\"\\\\\"+e\n",
    "    fil1 = images+\"\\\\train_\"+e\n",
    "    a = cv2.imread(fil)\n",
    "    a = cv2.resize(a, size)\n",
    "    cv2.imwrite(fil1, a)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772a12e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc0ef98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#顯示檔案的前幾行內容\n",
    "def view(nam, row):\n",
    "    with open(nam,\"rb\") as infile:  \n",
    "        c = (infile.read(5024))\n",
    "        [print(i) for i in c.split(b\"{\")]\n",
    "    return c  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f89786f",
   "metadata": {},
   "outputs": [],
   "source": [
    "view(r\"C:\\Users\\sky66\\fiftyone\\coco-2017\\raw\\captions_train2017.json\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa82a902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3b379b5",
   "metadata": {},
   "source": [
    "# 模組訓練(這裡程式碼沒調好，不用運行)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7456d406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae6b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9907e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 參考網站\n",
    "# https://www.kaggle.com/code/phylake1337/99-loss-simple-sol-using-u-net-keras-tf\n",
    "# https://github.com/petrosgk/Kaggle-Carvana-Image-Masking-Challenge/blob/master/model/u_net.py\n",
    "# https://www.gushiciku.cn/pl/pdkd/zh-tw\n",
    "# https://www.tensorflow.org/tutorials/keras/save_and_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5de902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv2plt(img_np):\n",
    "    img_np = cv2.cvtColor(img_np, cv2.COLOR_BGR2RGB)\n",
    "    img_np = img_np/255\n",
    "    return img_np\n",
    "\n",
    "def plt2cv(img_np):\n",
    "    return cv2.cvtColor((img_np*255).astype(\"uint8\"), cv2.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7137d801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    return img\n",
    "\n",
    "def load_mask(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    shp = img.shape\n",
    "    img = np.reshape(img, (shp[0], shp[1], 1))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01155505",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = load_mask(\"C:\\\\Users\\\\sky66\\\\fiftyone\\\\open-images-v6\\\\validation\\\\labels\\\\new\\\\c9c492853eb2af36.png\")\n",
    "b = load_img(\"C:\\\\Users\\\\sky66\\\\fiftyone\\\\open-images-v6\\\\validation\\\\labels\\\\new\\\\c9c492853eb2af36.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f80df4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e06715",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33edf351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e21cb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\sky66\\\\fiftyone\\\\open-images-v6\\\\validation\\\\labels\\\\new\"\n",
    "\n",
    "# 放mask\n",
    "newd = []\n",
    "\n",
    "# 放新圖片\n",
    "images = []\n",
    "\n",
    "for i in os.listdir(path):\n",
    "    if i.split(\".\")[1]==\"png\":\n",
    "        newd.append(i)\n",
    "    else:\n",
    "        images.append(i)\n",
    "        \n",
    "mask = sorted(newd)\n",
    "image = sorted(images)\n",
    "\n",
    "# 取訓練用的80%當驗證用圖片\n",
    "train = int(len(mask)*0.8)\n",
    "val = len(image)-train\n",
    "\n",
    "train_img = image[0:train]\n",
    "train_mask = mask[0:train]\n",
    "\n",
    "val_img = image[train:]\n",
    "val_mask = mask[train:]\n",
    "\n",
    "input_size = [256, 256, 3]\n",
    "\n",
    "def data_generator(images_path, masks_path, image_ids, mask_ids, batch_size, img_size=input_size):\n",
    "    '''\n",
    "    images_path/masks_path: Images/Masks folder directory.\n",
    "    images_ids/mask_ids: Ids for '.jpg' images/masks.\n",
    "    img_size: Generated imgs/masks size.\n",
    "    \n",
    "    returns: batch of randomly-selected car&mask images value-scaled (0 -> 1). \n",
    "    '''\n",
    "    data_size = len(image_ids)\n",
    "    while True:\n",
    "        #Choose random indice for later picking.\n",
    "        rnd_ind = np.random.choice(np.arange(data_size),batch_size)\n",
    "        imgs = []\n",
    "        masks = []\n",
    "        for i in rnd_ind:\n",
    "            #Pick a random id for car&mask images.\n",
    "            img_id, mask_id = image_ids[i], mask_ids[i]\n",
    "            #Load/resize images.\n",
    "            img = load_img(images_path +\"\\\\\" + img_id) \n",
    "            mask = load_mask(masks_path +\"\\\\\" + mask_id)\n",
    "            #Add to the batch data.\n",
    "            imgs.append(img)\n",
    "            masks.append(mask)\n",
    "        yield np.array(imgs, dtype=np.float16) / 255., np.array(masks, dtype=np.float16) / 255.\n",
    "        \n",
    "def dice_coef(y_true, y_pred):\n",
    "    '''\n",
    "    Metric\n",
    "    '''\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    '''\n",
    "    Loss function\n",
    "    '''\n",
    "    loss = 1 - dice_coef(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    '''\n",
    "    Mixed crossentropy and dice loss.\n",
    "    '''\n",
    "    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return loss     \n",
    "\n",
    "def get_unet_256(input_shape=(256, 256, 3),\n",
    "                 num_classes=1):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # 256\n",
    "\n",
    "    down0 = Conv2D(32, (3, 3), padding='same')(inputs)\n",
    "    down0 = BatchNormalization()(down0)\n",
    "    down0 = Activation('relu')(down0)\n",
    "    down0 = Conv2D(32, (3, 3), padding='same')(down0)\n",
    "    down0 = BatchNormalization()(down0)\n",
    "    down0 = Activation('relu')(down0)\n",
    "    down0_pool = MaxPooling2D((2, 2), strides=(2, 2))(down0)\n",
    "    # 128\n",
    "\n",
    "    down1 = Conv2D(64, (3, 3), padding='same')(down0_pool)\n",
    "    down1 = BatchNormalization()(down1)\n",
    "    down1 = Activation('relu')(down1)\n",
    "    down1 = Conv2D(64, (3, 3), padding='same')(down1)\n",
    "    down1 = BatchNormalization()(down1)\n",
    "    down1 = Activation('relu')(down1)\n",
    "    down1_pool = MaxPooling2D((2, 2), strides=(2, 2))(down1)\n",
    "    # 64\n",
    "\n",
    "    down2 = Conv2D(128, (3, 3), padding='same')(down1_pool)\n",
    "    down2 = BatchNormalization()(down2)\n",
    "    down2 = Activation('relu')(down2)\n",
    "    down2 = Conv2D(128, (3, 3), padding='same')(down2)\n",
    "    down2 = BatchNormalization()(down2)\n",
    "    down2 = Activation('relu')(down2)\n",
    "    down2_pool = MaxPooling2D((2, 2), strides=(2, 2))(down2)\n",
    "    # 32\n",
    "\n",
    "    down3 = Conv2D(256, (3, 3), padding='same')(down2_pool)\n",
    "    down3 = BatchNormalization()(down3)\n",
    "    down3 = Activation('relu')(down3)\n",
    "    down3 = Conv2D(256, (3, 3), padding='same')(down3)\n",
    "    down3 = BatchNormalization()(down3)\n",
    "    down3 = Activation('relu')(down3)\n",
    "    down3_pool = MaxPooling2D((2, 2), strides=(2, 2))(down3)\n",
    "    # 16\n",
    "\n",
    "    down4 = Conv2D(512, (3, 3), padding='same')(down3_pool)\n",
    "    down4 = BatchNormalization()(down4)\n",
    "    down4 = Activation('relu')(down4)\n",
    "    down4 = Conv2D(512, (3, 3), padding='same')(down4)\n",
    "    down4 = BatchNormalization()(down4)\n",
    "    down4 = Activation('relu')(down4)\n",
    "    down4_pool = MaxPooling2D((2, 2), strides=(2, 2))(down4)\n",
    "    # 8\n",
    "\n",
    "    center = Conv2D(1024, (3, 3), padding='same')(down4_pool)\n",
    "    center = BatchNormalization()(center)\n",
    "    center = Activation('relu')(center)\n",
    "    center = Conv2D(1024, (3, 3), padding='same')(center)\n",
    "    center = BatchNormalization()(center)\n",
    "    center = Activation('relu')(center)\n",
    "    # center\n",
    "\n",
    "    up4 = UpSampling2D((2, 2))(center)\n",
    "    up4 = concatenate([down4, up4], axis=3)\n",
    "    up4 = Conv2D(512, (3, 3), padding='same')(up4)\n",
    "    up4 = BatchNormalization()(up4)\n",
    "    up4 = Activation('relu')(up4)\n",
    "    up4 = Conv2D(512, (3, 3), padding='same')(up4)\n",
    "    up4 = BatchNormalization()(up4)\n",
    "    up4 = Activation('relu')(up4)\n",
    "    up4 = Conv2D(512, (3, 3), padding='same')(up4)\n",
    "    up4 = BatchNormalization()(up4)\n",
    "    up4 = Activation('relu')(up4)\n",
    "    # 16\n",
    "\n",
    "    up3 = UpSampling2D((2, 2))(up4)\n",
    "    up3 = concatenate([down3, up3], axis=3)\n",
    "    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n",
    "    up3 = BatchNormalization()(up3)\n",
    "    up3 = Activation('relu')(up3)\n",
    "    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n",
    "    up3 = BatchNormalization()(up3)\n",
    "    up3 = Activation('relu')(up3)\n",
    "    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n",
    "    up3 = BatchNormalization()(up3)\n",
    "    up3 = Activation('relu')(up3)\n",
    "    # 32\n",
    "\n",
    "    up2 = UpSampling2D((2, 2))(up3)\n",
    "    up2 = concatenate([down2, up2], axis=3)\n",
    "    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n",
    "    up2 = BatchNormalization()(up2)\n",
    "    up2 = Activation('relu')(up2)\n",
    "    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n",
    "    up2 = BatchNormalization()(up2)\n",
    "    up2 = Activation('relu')(up2)\n",
    "    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n",
    "    up2 = BatchNormalization()(up2)\n",
    "    up2 = Activation('relu')(up2)\n",
    "    # 64\n",
    "\n",
    "    up1 = UpSampling2D((2, 2))(up2)\n",
    "    up1 = concatenate([down1, up1], axis=3)\n",
    "    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "    up1 = BatchNormalization()(up1)\n",
    "    up1 = Activation('relu')(up1)\n",
    "    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "    up1 = BatchNormalization()(up1)\n",
    "    up1 = Activation('relu')(up1)\n",
    "    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "    up1 = BatchNormalization()(up1)\n",
    "    up1 = Activation('relu')(up1)\n",
    "    # 128\n",
    "\n",
    "    up0 = UpSampling2D((2, 2))(up1)\n",
    "    up0 = concatenate([down0, up0], axis=3)\n",
    "    up0 = Conv2D(32, (3, 3), padding='same')(up0)\n",
    "    up0 = BatchNormalization()(up0)\n",
    "    up0 = Activation('relu')(up0)\n",
    "    up0 = Conv2D(32, (3, 3), padding='same')(up0)\n",
    "    up0 = BatchNormalization()(up0)\n",
    "    up0 = Activation('relu')(up0)\n",
    "    up0 = Conv2D(32, (3, 3), padding='same')(up0)\n",
    "    up0 = BatchNormalization()(up0)\n",
    "    up0 = Activation('relu')(up0)\n",
    "    # 256\n",
    "\n",
    "    classify = Conv2D(num_classes, (1, 1), activation='sigmoid')(up0)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=classify)\n",
    "\n",
    "    model.compile(optimizer=RMSprop(lr=0.0001), loss=bce_dice_loss, metrics=[dice_coef])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6da5dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目標模組\n",
    "uNet = get_unet_256()\n",
    "\n",
    "#Prepare callbacks\n",
    "LR_callback = ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=10, factor=.2, min_lr=.00001)\n",
    "EarlyStop_callback = EarlyStopping(monitor='val_loss',patience=10, restore_best_weights=True)\n",
    "\n",
    "#Perpare data generators.\n",
    "batch_size = 5\n",
    "train_gen = data_generator(path, path, train_img, train_mask, batch_size=batch_size)\n",
    "val_gen = data_generator(path, path, val_img, val_mask, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543a35f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 開始訓練\n",
    "history = uNet.fit_generator(train_gen, steps_per_epoch=int(train/batch_size),\n",
    "                             epochs=35, validation_data=val_gen,\n",
    "                             validation_steps=int(val/batch_size),\n",
    "                             callbacks=[LR_callback, EarlyStop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fee26c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd1dc72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b81a47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c3e616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c832fdd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576ec5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe00d63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21591c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345969e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f804b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faadea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d9ce28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
