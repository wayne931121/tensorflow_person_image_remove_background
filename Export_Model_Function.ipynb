{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d828523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e981c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Dectection_Model_Not_Export(pipeline_config, checkpoint_path):\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n",
    "    model_config = configs['model']\n",
    "    # model_config.ssd.freeze_batchnorm = True\n",
    "    detection_model = model_builder.build(\n",
    "          model_config=model_config, is_training=True)\n",
    "    \n",
    "    fake_box_predictor = tf.compat.v2.train.Checkpoint(\n",
    "        _base_tower_layers_for_heads=detection_model._box_predictor._base_tower_layers_for_heads,\n",
    "        _prediction_heads=detection_model._box_predictor._prediction_heads,\n",
    "        _box_prediction_head=detection_model._box_predictor._box_prediction_head,\n",
    "        )\n",
    "    \n",
    "    fake_model = tf.compat.v2.train.Checkpoint(\n",
    "              _feature_extractor=detection_model._feature_extractor,\n",
    "              _box_predictor=fake_box_predictor)\n",
    "    ckpt = tf.compat.v2.train.Checkpoint(model=fake_model)\n",
    "    ckpt_manager = tf.train.CheckpointManager(ckpt, directory=checkpoint_path, max_to_keep=5)\n",
    "    print(ckpt_manager.latest_checkpoint)\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    # ckpt.restore(checkpoint_path).expect_partial()\n",
    "    \n",
    "    # Run model through a dummy image so that variables are created\n",
    "    image, shapes = detection_model.preprocess(tf.zeros([1, 640, 640, 3]))\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    _ = detection_model.postprocess(prediction_dict, shapes)\n",
    "    print('Weights restored!')\n",
    "    return detection_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "497b3f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sky66\\Downloads\\models\\research\\ckpt\\ckpt-1\n",
      "Weights restored!\n"
     ]
    }
   ],
   "source": [
    "pipeline_config = r\"C:\\Users\\sky66\\Downloads\\models\\research\\ckpt\\pipeline.config\"\n",
    "checkpoint_path = r\"C:\\Users\\sky66\\Downloads\\models\\research\\ckpt\"\n",
    "detection_model = Get_Dectection_Model_Not_Export(pipeline_config, checkpoint_path)\n",
    "\n",
    "@tf.function(input_signature=[tf.TensorSpec(shape=[None,640,640,3], dtype=tf.float32)])\n",
    "def detect(input_tensor):\n",
    "    # Note that the first frame will trigger tracing of the tf.function, which will\n",
    "    # take some time, after which inference should be fast. \n",
    "    \"\"\"Run detection on an input image.\n",
    "    \n",
    "    Args:\n",
    "      input_tensor: A [1, height, width, 3] Tensor of type tf.float32.\n",
    "        Note that height and width can be anything since the image will be\n",
    "        immediately resized according to the needs of the model within this\n",
    "        function.\n",
    "    \n",
    "    Returns:\n",
    "      A dict containing 3 Tensors (`detection_boxes`, `detection_classes`,\n",
    "        and `detection_scores`).\n",
    "    \"\"\"\n",
    "    preprocessed_image, shapes = detection_model.preprocess(input_tensor)\n",
    "    prediction_dict = detection_model.predict(preprocessed_image, shapes)\n",
    "    return detection_model.postprocess(prediction_dict, shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adf756b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sky66\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow-2.8.0-py3.9-win-amd64.egg\\tensorflow\\python\\autograph\\impl\\api.py:459: calling map_fn (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x0000026A070E67F0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 208). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: detection_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: detection_model\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(\n",
    "    detection_model , 'detection_model',\n",
    "    signatures={\n",
    "      'detection': detect.get_concrete_function()\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a42174",
   "metadata": {},
   "source": [
    "# Use 7zip to compose the model folder,\n",
    "# create \"detection model for google drive\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1169e2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 為了防止 colab gdown 下載檔案時因檔案過大而出現無法掃描病毒，造成下載失敗。\n",
    "def export_for_google_drive(file, target_folder, size = 10*1024*1024):\n",
    "    target_folder_files = target_folder+\"\\\\%d\"\n",
    "    \n",
    "    # Make target folder is empty.\n",
    "    for e in os.listdir(target_folder):\n",
    "        f = target_folder+\"\\\\\"+e\n",
    "        os.remove(f)\n",
    "    \n",
    "    # Read source file, then write them to files by numbers.\n",
    "    with open(file, \"rb\") as f:\n",
    "        # 每個檔案大小 10MB\n",
    "        # size = 10*1024*1024 # 單位 bytes\n",
    "        i = 1\n",
    "        while True:\n",
    "            tmp = f.read(size)\n",
    "            \n",
    "            if len(tmp)==0 :\n",
    "                break\n",
    "            \n",
    "            with open(target_folder_files%i, \"wb\") as gf:\n",
    "                gf.write(tmp)\n",
    "                \n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb611fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(\"detection model for google drive\")\n",
    "    os.mkdir(\"UNet model for google drive\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "897007f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit 25MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ab3fdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"detection_model.zip\"\n",
    "target = \"detection model for google drive\"\n",
    "export_for_google_drive(file, target, 20*1024*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1942487",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"C:\\Users\\sky66\\Desktop\\my_model.zip\"\n",
    "target = \"UNet model for google drive\"\n",
    "export_for_google_drive(file, target, 20*1024*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "819d8ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_from_split_file(source_folder, target_file):\n",
    "    # create a empty file\n",
    "    with open(target_file, \"wb\") as gf:\n",
    "        gf.write(b\"\")\n",
    "    \n",
    "    # write all buffers to a new file\n",
    "    export = sorted([int(i) for i in os.listdir(source_folder)])\n",
    "    # For each source file, we read it, apppending to new file.\n",
    "    with open(target_file, \"ab\") as f:\n",
    "        \n",
    "        for _ in export:\n",
    "            tmp = source_folder+\"\\\\\"+str(_)\n",
    "            \n",
    "            with open(tmp, \"rb\") as f1:\n",
    "                tmp = f1.read(-1)\n",
    "            \n",
    "            f.write(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99ad38dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_file = \"new_detection_model.zip\"\n",
    "# folder = \"detection model for google drive\"\n",
    "# export_from_split_file(folder, new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ed15f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!gdown --no-cookies --folder \"ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07306bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
